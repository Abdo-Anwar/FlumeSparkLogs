## Configuring Components
a1.sources=source1
a1.channels=channel1
a1.sinks=sink1


## Configuring Source
## if sys log 
##a1.sources = r1
##a1.channels = c1
##a1.sources.r1.type = syslogtcp
##a1.sources.r1.port = 5140
##a1.sources.r1.host = localhost
##a1.sources.r1.channels = c1

## soruce is normal log file in the machine 


a1.sources.source1.type=exec
a1.sources.source1.command = /usr/bin/tail -F /home/bigdata/genLog.log
a1.sources.source1.shell = /bin/bash -c
a1.sources.source1.channels=channel1


a1.sources.source1.interceptors = i1
a1.sources.source1.interceptors.i1.type = timestamp

##a1.sources.source1.zookeeperConnect=localhost:2181
##a1.sources.source1.topic=bigdata
##a1.sources.source1.groupId=flume
##
##a1.sources.source1.interceptors=i1
##a1.sources.source1.interceptors.i1.type=timestamp
##a1.sources.source1.kafka.consumer.timeout.ms=100



## Configuring Channel
a1.channels.channel1.type=memory
a1.channels.channel1.capacity=10000
a1.channels.channel1.transactionCapacity=1000

## Configuring sink
a1.sinks.sink1.type=hdfs
a1.sinks.sink1.channel=channel1
a1.sinks.sink1.hdfs.path=/tmp/logGenED/%y-%m-%d
a1.sinks.sink1.hdfs.writeFormat = Text


## Number of seconds to wait before rolling current file
a1.sinks.sink1.hdfs.rollInterval=50
## File size to trigger roll, in byte
a1.sinks.sink1.hdfs.rollSize=1024
## Number of events written to file before it rolled
a1.sinks.sink1.hdfs.rollCount=10
## DataStrem - Stores data instead of ASCII values of data
a1.sinks.sink1.hdfs.fileType=DataStream



